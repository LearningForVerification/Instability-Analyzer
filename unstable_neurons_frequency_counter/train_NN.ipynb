{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T12:29:35.364214Z",
     "start_time": "2024-09-24T12:29:29.687052Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import onnx\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "\n",
    "# Constants\n",
    "INPUT_DIM = 784  # after flattening\n",
    "OUTPUT_DIM = 10\n",
    "DATASET_DIR = '../dataset'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Data loading and transformations\n",
    "transform = tr.Compose([\n",
    "    tr.ToTensor(),\n",
    "    tr.Lambda(lambda x: torch.flatten(x))  # Flatten the image\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(DATASET_DIR, train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(DATASET_DIR, train=False, download=True, transform=transform)\n",
    "\n",
    "# Creating subsets and data loaders\n",
    "train_subset = Subset(train_dataset, indices=np.arange(4000))\n",
    "train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "class SmallNetwork(nn.Module):\n",
    "    def __init__(self, architecture):\n",
    "        super(SmallNetwork, self).__init__()\n",
    "        layers = []\n",
    "        input_size = INPUT_DIM\n",
    "\n",
    "        for i, layer_size in enumerate(architecture):\n",
    "            layers.append(nn.Linear(input_size, layer_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_size = layer_size\n",
    "\n",
    "        layers.append(nn.Linear(input_size, OUTPUT_DIM))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "def train_mnist_network(architecture, folder_path):\n",
    "    print(f\"Architecture: {architecture}\")\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    # Building the network\n",
    "    model = SmallNetwork(architecture).to(device)\n",
    "\n",
    "    # Initialization of the training parameters\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    epochs = 1\n",
    "\n",
    "    optimizer = opt.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        test_accuracy = 100 * correct / total\n",
    "        test_loss = test_loss / len(test_loader)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, \"\n",
    "              f\"Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "    # Save the model in ONNX format\n",
    "    dummy_input = torch.randn(1, INPUT_DIM, device=device)\n",
    "    onnx_path = f\"{folder_path}/baseline_{architecture[0]}.onnx\"\n",
    "    torch.onnx.export(model, dummy_input, onnx_path)\n",
    "    print(f\"Model saved to {onnx_path}\")\n",
    "\n",
    "    return {\n",
    "        \"architecture\": architecture,\n",
    "        \"train_accuracy\": train_accuracies[-1],\n",
    "        \"test_accuracy\": test_accuracies[-1],\n",
    "        \"train_loss\": train_losses[-1],\n",
    "        \"test_loss\": test_losses[-1],\n",
    "    }\n",
    "\n",
    "\n",
    "# Writing results to CSV file\n",
    "csv_file = \"accuracies_losses.csv\"\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Architecture\", \"Train Accuracy\", \"Test Accuracy\", \"Train Loss\", \"Test Loss\"])\n",
    "\n",
    "    architectures = [ [200]]\n",
    "\n",
    "    for architecture in architectures:\n",
    "        folder_path = \"output_folder\"\n",
    "        results = train_mnist_network(architecture, folder_path)\n",
    "        print(results)\n",
    "\n",
    "        # Write the architecture, accuracies, and losses to the CSV file\n",
    "        writer.writerow([architecture, results['train_accuracy'], results['test_accuracy'],\n",
    "                         results['train_loss'], results['test_loss']])\n",
    "\n",
    "print(f\"Results saved to {csv_file}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture: [7]\n",
      "Device: cuda\n",
      "Epoch [1/1], Train Loss: 2.1641, Test Loss: 2.0082, Train Accuracy: 24.18%, Test Accuracy: 35.75%\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output_folder/baseline_7.onnx'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 149\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m architecture \u001B[38;5;129;01min\u001B[39;00m architectures:\n\u001B[0;32m    148\u001B[0m     folder_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_folder\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 149\u001B[0m     results \u001B[38;5;241m=\u001B[39m train_mnist_network(architecture, folder_path)\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;28mprint\u001B[39m(results)\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;66;03m# Write the architecture, accuracies, and losses to the CSV file\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[3], line 126\u001B[0m, in \u001B[0;36mtrain_mnist_network\u001B[1;34m(architecture, folder_path)\u001B[0m\n\u001B[0;32m    124\u001B[0m dummy_input \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m1\u001B[39m, INPUT_DIM, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m    125\u001B[0m onnx_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfolder_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/baseline_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00marchitecture[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 126\u001B[0m torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mexport(model, dummy_input, onnx_path)\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel saved to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00monnx_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m    130\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marchitecture\u001B[39m\u001B[38;5;124m\"\u001B[39m: architecture,\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m: train_accuracies[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m: test_losses[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m    135\u001B[0m }\n",
      "File \u001B[1;32m~\\.conda\\envs\\Belkin-Paper\\Lib\\site-packages\\torch\\onnx\\utils.py:506\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001B[0m\n\u001B[0;32m    188\u001B[0m \u001B[38;5;129m@_beartype\u001B[39m\u001B[38;5;241m.\u001B[39mbeartype\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mexport\u001B[39m(\n\u001B[0;32m    190\u001B[0m     model: Union[torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule, torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mScriptModule, torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mScriptFunction],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    206\u001B[0m     export_modules_as_functions: Union[\u001B[38;5;28mbool\u001B[39m, Collection[Type[torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mModule]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    207\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    208\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001B[39;00m\n\u001B[0;32m    209\u001B[0m \n\u001B[0;32m    210\u001B[0m \u001B[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    503\u001B[0m \u001B[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001B[39;00m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 506\u001B[0m     _export(\n\u001B[0;32m    507\u001B[0m         model,\n\u001B[0;32m    508\u001B[0m         args,\n\u001B[0;32m    509\u001B[0m         f,\n\u001B[0;32m    510\u001B[0m         export_params,\n\u001B[0;32m    511\u001B[0m         verbose,\n\u001B[0;32m    512\u001B[0m         training,\n\u001B[0;32m    513\u001B[0m         input_names,\n\u001B[0;32m    514\u001B[0m         output_names,\n\u001B[0;32m    515\u001B[0m         operator_export_type\u001B[38;5;241m=\u001B[39moperator_export_type,\n\u001B[0;32m    516\u001B[0m         opset_version\u001B[38;5;241m=\u001B[39mopset_version,\n\u001B[0;32m    517\u001B[0m         do_constant_folding\u001B[38;5;241m=\u001B[39mdo_constant_folding,\n\u001B[0;32m    518\u001B[0m         dynamic_axes\u001B[38;5;241m=\u001B[39mdynamic_axes,\n\u001B[0;32m    519\u001B[0m         keep_initializers_as_inputs\u001B[38;5;241m=\u001B[39mkeep_initializers_as_inputs,\n\u001B[0;32m    520\u001B[0m         custom_opsets\u001B[38;5;241m=\u001B[39mcustom_opsets,\n\u001B[0;32m    521\u001B[0m         export_modules_as_functions\u001B[38;5;241m=\u001B[39mexport_modules_as_functions,\n\u001B[0;32m    522\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\Belkin-Paper\\Lib\\site-packages\\torch\\onnx\\utils.py:1626\u001B[0m, in \u001B[0;36m_export\u001B[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001B[0m\n\u001B[0;32m   1624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m verbose:\n\u001B[0;32m   1625\u001B[0m     torch\u001B[38;5;241m.\u001B[39monnx\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExported graph: \u001B[39m\u001B[38;5;124m\"\u001B[39m, graph)\n\u001B[1;32m-> 1626\u001B[0m onnx_proto_utils\u001B[38;5;241m.\u001B[39m_export_file(proto, f, export_type, export_map)\n\u001B[0;32m   1627\u001B[0m \u001B[38;5;66;03m# The ONNX checker only works for ONNX graph. So if the operator_export_type is not ONNX,\u001B[39;00m\n\u001B[0;32m   1628\u001B[0m \u001B[38;5;66;03m# we can skip this check.\u001B[39;00m\n\u001B[0;32m   1629\u001B[0m \u001B[38;5;66;03m# If large model format export is enabled, proto will only contain data location instead of\u001B[39;00m\n\u001B[0;32m   1630\u001B[0m \u001B[38;5;66;03m# raw data and _check_onnx_proto() will fail because it can only handle the raw ONNX proto\u001B[39;00m\n\u001B[0;32m   1631\u001B[0m \u001B[38;5;66;03m# string in memory.\u001B[39;00m\n\u001B[0;32m   1632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (operator_export_type \u001B[38;5;129;01mis\u001B[39;00m _C_onnx\u001B[38;5;241m.\u001B[39mOperatorExportTypes\u001B[38;5;241m.\u001B[39mONNX) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[0;32m   1633\u001B[0m     \u001B[38;5;129;01mnot\u001B[39;00m val_use_external_data_format\n\u001B[0;32m   1634\u001B[0m ):\n",
      "File \u001B[1;32m~\\.conda\\envs\\Belkin-Paper\\Lib\\site-packages\\torch\\onnx\\_internal\\onnx_proto_utils.py:174\u001B[0m, in \u001B[0;36m_export_file\u001B[1;34m(model_bytes, f, export_type, export_map)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m export_type \u001B[38;5;241m==\u001B[39m _exporter_states\u001B[38;5;241m.\u001B[39mExportTypes\u001B[38;5;241m.\u001B[39mPROTOBUF_FILE:\n\u001B[0;32m    173\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(export_map) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 174\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mserialization\u001B[38;5;241m.\u001B[39m_open_file_like(f, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    175\u001B[0m         opened_file\u001B[38;5;241m.\u001B[39mwrite(model_bytes)\n\u001B[0;32m    176\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m export_type \u001B[38;5;129;01min\u001B[39;00m {\n\u001B[0;32m    177\u001B[0m     _exporter_states\u001B[38;5;241m.\u001B[39mExportTypes\u001B[38;5;241m.\u001B[39mZIP_ARCHIVE,\n\u001B[0;32m    178\u001B[0m     _exporter_states\u001B[38;5;241m.\u001B[39mExportTypes\u001B[38;5;241m.\u001B[39mCOMPRESSED_ZIP_ARCHIVE,\n\u001B[0;32m    179\u001B[0m }:\n",
      "File \u001B[1;32m~\\.conda\\envs\\Belkin-Paper\\Lib\\site-packages\\torch\\serialization.py:271\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 271\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _open_file(name_or_buffer, mode)\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    273\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\.conda\\envs\\Belkin-Paper\\Lib\\site-packages\\torch\\serialization.py:252\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 252\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mopen\u001B[39m(name, mode))\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'output_folder/baseline_7.onnx'"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
